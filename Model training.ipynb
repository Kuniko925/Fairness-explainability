{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38524244-74e7-4e2d-bae6-b3121db1b59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\hampy\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import cv2\n",
    "\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be922b36-aedd-4562-9689-04150fb7395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"d:/ham/\"\n",
    "train_df = pd.read_csv(root + \"working/train_df.csv\")\n",
    "valid_df = pd.read_csv(root + \"working/valid_df.csv\")\n",
    "test_df = pd.read_csv(root + \"working/test_df.csv\")\n",
    "\n",
    "train_df[\"labels\"] = train_df['labels'].apply(lambda x: str(x))\n",
    "valid_df[\"labels\"] = valid_df['labels'].apply(lambda x: str(x))\n",
    "test_df[\"labels\"] = test_df['labels'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e079e3d-fcfa-46c4-8213-b8ad496c2c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49000 entries, 0 to 48999\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   lesion_id     3648 non-null   object \n",
      " 1   image_id      3648 non-null   object \n",
      " 2   dx            3648 non-null   object \n",
      " 3   dx_type       3648 non-null   object \n",
      " 4   age           3636 non-null   float64\n",
      " 5   sex           3648 non-null   object \n",
      " 6   localization  3648 non-null   object \n",
      " 7   filepaths     49000 non-null  object \n",
      " 8   cell_type     3648 non-null   object \n",
      " 9   labels        49000 non-null  object \n",
      " 10  ita           3648 non-null   float64\n",
      " 11  ita labels    3648 non-null   float64\n",
      "dtypes: float64(3), object(9)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08a69379-fac4-4fd9-9fa1-d86934d7e9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1001 entries, 0 to 1000\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   lesion_id     1001 non-null   object \n",
      " 1   image_id      1001 non-null   object \n",
      " 2   dx            1001 non-null   object \n",
      " 3   dx_type       1001 non-null   object \n",
      " 4   age           996 non-null    float64\n",
      " 5   sex           1001 non-null   object \n",
      " 6   localization  1001 non-null   object \n",
      " 7   filepaths     1001 non-null   object \n",
      " 8   cell_type     1001 non-null   object \n",
      " 9   labels        1001 non-null   object \n",
      " 10  ita           1001 non-null   float64\n",
      " 11  ita labels    1001 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(9)\n",
      "memory usage: 94.0+ KB\n"
     ]
    }
   ],
   "source": [
    "valid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98ae20fb-23c8-474f-afc3-3b5a89d7ed82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49000 validated image filenames belonging to 7 classes.          for train generator \n",
      "Found 1001 validated image filenames belonging to 7 classes.           for valid generator \n",
      "Found 1002 validated image filenames belonging to 7 classes.           for test generator \n",
      "test batch size:  6   test steps:  167  number of classes :  7\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def make_gens(batch_size, ycol, train_df, test_df, valid_df, img_size):\n",
    "    trgen=ImageDataGenerator(horizontal_flip=True)    \n",
    "    t_and_v_gen=ImageDataGenerator()\n",
    "    msg='{0:70s} for train generator'.format(' ')\n",
    "    print(msg, '\\r', end='') # prints over on the same line\n",
    "    train_gen=trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col=ycol, target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "    msg='{0:70s} for valid generator'.format(' ')\n",
    "    print(msg, '\\r', end='') # prints over on the same line\n",
    "    valid_gen=t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col=ycol, target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n",
    "    # for the test_gen we want to calculate the batch size and test steps such that batch_size X test_steps= number of samples in test set\n",
    "    # this insures that we go through all the sample in the test set exactly once.\n",
    "    length=len(test_df)\n",
    "    test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n",
    "    test_steps=int(length/test_batch_size)    \n",
    "    msg='{0:70s} for test generator'.format(' ')\n",
    "    print(msg, '\\r', end='') # prints over on the same line\n",
    "    test_gen=t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col=ycol, target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
    "    # from the generator we can get information we will need later\n",
    "    classes=list(train_gen.class_indices.keys())\n",
    "    class_indices=list(train_gen.class_indices.values())\n",
    "    class_count=len(classes)\n",
    "    labels=test_gen.labels\n",
    "    print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps, ' number of classes : ', class_count)\n",
    "    return train_gen, test_gen, valid_gen, test_steps\n",
    "\n",
    "bs=16\n",
    "img_size = (310,640)\n",
    "ycol='labels'\n",
    "train_gen, test_gen, valid_gen, test_steps = make_gens(bs, ycol, train_df, test_df, valid_df, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba37aa7a-2859-4a7a-9b79-f85ff9ec0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff84940e-3463-48aa-994f-1a20af58d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_in_color(txt_msg,fore_tupple=(0,255,255),back_tupple=(100,100,100)):\n",
    "    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n",
    "    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n",
    "    # default parameter print in cyan foreground and gray background\n",
    "    rf,gf,bf=fore_tupple\n",
    "    rb,gb,bb=back_tupple\n",
    "    msg='{0}' + txt_msg\n",
    "    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n",
    "    print(msg .format(mat), flush=True)\n",
    "    print('\\33[0m', flush=True) # returns default print color to back to black\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a276e55a-1e49-4402-884c-05a88ddf1a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;0;255;255;48;2;100;100;100mCreated EfficientNet B3 model with initial learning rate set to 0.001\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "def make_model(img_size, lr, mod_num=3):  \n",
    "    img_shape=(img_size[0], img_size[1], 3)\n",
    "    if mod_num == 0:\n",
    "        base_model=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max')\n",
    "        msg='Created EfficientNet B0 model'\n",
    "    elif mod_num == 3:\n",
    "        base_model=tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n",
    "        msg='Created EfficientNet B3 model'\n",
    "    elif mod_num == 5:\n",
    "        base_model=tf.keras.applications.efficientnet.EfficientNetB5(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n",
    "        msg='Created EfficientNet B5 model'\n",
    "        \n",
    "    else:\n",
    "        base_model=tf.keras.applications.efficientnet.EfficientNetB7(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max')\n",
    "        msg='Created EfficientNet B7 model'   \n",
    "       \n",
    "    base_model.trainable= True\n",
    "\n",
    "    x=base_model.output\n",
    "    x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
    "    x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                    bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
    "    x=Dropout(rate=.4, seed=123)(x)       \n",
    "    output=Dense(class_count, activation='softmax')(x)\n",
    "    model=Model(inputs=base_model.input, outputs=output)\n",
    "    # Evidential Begins\n",
    "    model.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy', F1_score, 'AUC']) \n",
    "    msg=msg + f' with initial learning rate set to {lr}'\n",
    "    print_in_color(msg)\n",
    "    return model\n",
    "\n",
    "class_count=7\n",
    "lr=.001\n",
    "model=make_model(img_size, lr) # using B3 model by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c0d89ac-563e-4aea-94ec-71ae2021fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_ASK(keras.callbacks.Callback):\n",
    "    def __init__ (self, model, epochs,  ask_epoch, dwell=True, factor=.4): # initialization of the callback\n",
    "        super(LR_ASK, self).__init__()\n",
    "        self.model=model               \n",
    "        self.ask_epoch=ask_epoch\n",
    "        self.epochs=epochs\n",
    "        self.ask=True # if True query the user on a specified epoch\n",
    "        self.lowest_vloss=np.inf\n",
    "        self.lowest_aloss=np.inf\n",
    "        self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n",
    "        self.best_epoch=1\n",
    "        self.plist=[]\n",
    "        self.alist=[]\n",
    "        self.dwell= dwell\n",
    "        self.factor=factor\n",
    "\n",
    "    def get_list(self): # define a function to return the list of % validation change\n",
    "        return self.plist, self.alist\n",
    "    def on_train_begin(self, logs=None): # this runs on the beginning of training\n",
    "        if self.ask_epoch == 0: \n",
    "            print('you set ask_epoch = 0, ask_epoch will be set to 1', flush=True)\n",
    "            self.ask_epoch=1\n",
    "        if self.ask_epoch >= self.epochs: # you are running for epochs but ask_epoch>epochs\n",
    "            print('ask_epoch >= epochs, will train for ', epochs, ' epochs', flush=True)\n",
    "            self.ask=False # do not query the user\n",
    "        if self.epochs == 1:\n",
    "            self.ask=False # running only for 1 epoch so do not query user\n",
    "        else:\n",
    "            msg =f'Training will proceed until epoch {ask_epoch} then you will be asked to' \n",
    "            print_in_color(msg )\n",
    "            msg='enter H to halt training or enter an integer for how many more epochs to run then be asked again'\n",
    "            print_in_color(msg)\n",
    "            if self.dwell:\n",
    "                msg='learning rate will be automatically adjusted during training'\n",
    "                print_in_color(msg, (0,255,0))\n",
    "        self.start_time= time.time() # set the time at which training started\n",
    "\n",
    "    def on_train_end(self, logs=None):   # runs at the end of training  \n",
    "        msg=f'loading model with weights from epoch {self.best_epoch}'\n",
    "        print_in_color(msg, (0,255,255))\n",
    "        self.model.set_weights(self.best_weights) # set the weights of the model to the best weights\n",
    "        tr_duration=time.time() - self.start_time   # determine how long the training cycle lasted         \n",
    "        hours = tr_duration // 3600\n",
    "        minutes = (tr_duration - (hours * 3600)) // 60\n",
    "        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n",
    "        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n",
    "        print_in_color (msg) # print out training duration time\n",
    "    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n",
    "        vloss=logs.get('val_loss')  # get the validation loss for this epoch\n",
    "        aloss=logs.get('loss')\n",
    "        if epoch >0:\n",
    "            deltav = self.lowest_vloss- vloss \n",
    "            pimprov=(deltav/self.lowest_vloss) * 100 \n",
    "            self.plist.append(pimprov)\n",
    "            deltaa=self.lowest_aloss-aloss\n",
    "            aimprov=(deltaa/self.lowest_aloss) * 100\n",
    "            self.alist.append(aimprov)\n",
    "        else:\n",
    "            pimprov=0.0 \n",
    "            aimprov=0.0\n",
    "        if vloss< self.lowest_vloss:\n",
    "            self.lowest_vloss=vloss\n",
    "            self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n",
    "            self.best_epoch=epoch + 1            \n",
    "            msg=f'\\n validation loss of {vloss:7.4f} is {pimprov:7.4f} % below lowest loss, saving weights from epoch {str(epoch + 1):3s} as best weights'\n",
    "            print_in_color(msg, (0,255,0)) # green foreground\n",
    "\n",
    "        else: # validation loss increased\n",
    "            pimprov=abs(pimprov)\n",
    "            msg=f'\\n validation loss of {vloss:7.4f} is {pimprov:7.4f} % above lowest loss of {self.lowest_vloss:7.4f} keeping weights from epoch {str(self.best_epoch)} as best weights'\n",
    "            print_in_color(msg, (255,255,0)) # yellow foreground\n",
    "            if self.dwell: # if dwell is True when the validation loss increases the learning rate is automatically reduced and model weights are set to best weights\n",
    "                lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "                new_lr=lr * self.factor\n",
    "                msg=f'learning rate was automatically adjusted from {lr:8.6f} to {new_lr:8.6f}, model weights set to best weights'\n",
    "                print_in_color(msg) # cyan foreground\n",
    "                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n",
    "                self.model.set_weights(self.best_weights) # set the weights of the model to the best weights      \n",
    "\n",
    "        if aloss< self.lowest_aloss:\n",
    "            self.lowest_aloss=aloss        \n",
    "        if self.ask: # are the conditions right to query the user?\n",
    "            if epoch + 1 ==self.ask_epoch: # is this epoch the one for quering the user?\n",
    "                msg='press enter to continue or enter a comment  below '\n",
    "                print_in_color(msg)\n",
    "                comment=input(' ')\n",
    "                if comment !='':\n",
    "                    comment = 'User comment: ' + comment\n",
    "                    print_in_color(comment, (155,245,66))\n",
    "                msg='\\n Enter H to end training or  an integer for the number of additional epochs to run then ask again'\n",
    "                print_in_color(msg) # cyan foreground\n",
    "                ans=input()\n",
    "                \n",
    "                if ans == 'H' or ans =='h' or ans == '0': # quit training for these conditions\n",
    "                    msg=f'you entered {ans},  Training halted on epoch {epoch+1} due to user input\\n'\n",
    "                    print_in_color(msg)\n",
    "                    self.model.stop_training = True # halt training\n",
    "                else: # user wants to continue training\n",
    "                    self.ask_epoch += int(ans)\n",
    "                    if self.ask_epoch > self.epochs:\n",
    "                        print('\\nYou specified maximum epochs of as ', self.epochs, ' cannot train for ', self.ask_epoch, flush =True)\n",
    "                    else:\n",
    "                        msg=f'you entered {ans} Training will continue to epoch {self.ask_epoch}'\n",
    "                        print_in_color(msg) # cyan foreground\n",
    "                        if self.dwell==False:\n",
    "                            lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "                            msg=f'current LR is  {lr:8.6f}  hit enter to keep  this LR or enter a new LR'\n",
    "                            print_in_color(msg) # cyan foreground\n",
    "                            ans=input(' ')\n",
    "                            if ans =='':\n",
    "                                msg=f'keeping current LR of {lr:7.5f}'\n",
    "                                print_in_color(msg) # cyan foreground\n",
    "                            else:\n",
    "                                new_lr=float(ans)\n",
    "                                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n",
    "                                msg=f' changing LR to {ans}'\n",
    "                                print_in_color(msg) # cyan foreground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bbbb2c0-76e1-49dd-b2a2-355a574a11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "ask_epoch = 2\n",
    "ask=LR_ASK(model, epochs,  ask_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4da70b93-440b-4510-8907-172862ede0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "WARNING:tensorflow:From C:\\hampy\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "  25/3063 [..............................] - ETA: 20:41:44 - loss: 9.8857 - accuracy: 0.2750 - F1_score: 0.2365 - auc: 0.6799"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "history=model.fit(x=train_gen, epochs=epochs, verbose=1, validation_data=valid_gen,\n",
    "               validation_steps=None,  shuffle=False,  initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd323285-4d13-485f-8123-36e2a6beee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_plot(tr_data):\n",
    "    start_epoch=0\n",
    "    #Plot the training and validation data\n",
    "    tacc=tr_data.history['accuracy']\n",
    "    tloss=tr_data.history['loss']\n",
    "    vacc=tr_data.history['val_accuracy']\n",
    "    vloss=tr_data.history['val_loss']\n",
    "    tf1=tr_data.history['F1_score']\n",
    "    vf1=tr_data.history['val_F1_score']\n",
    "    tauc=tr_data.history['auc']\n",
    "    vauc=tr_data.history['val_auc']\n",
    "    Epoch_count=len(tacc)+ start_epoch\n",
    "    Epochs=[]\n",
    "    for i in range (start_epoch ,Epoch_count):\n",
    "        Epochs.append(i+1)\n",
    "    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
    "    val_lowest=vloss[index_loss]\n",
    "    index_acc=np.argmax(vacc)\n",
    "    acc_highest=vacc[index_acc]\n",
    "    auc_index=np.argmax(vauc)\n",
    "    val_highest_auc=vauc[auc_index]\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n",
    "    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n",
    "    auc_label='best epoch= ' + str(auc_index + 1 + start_epoch)\n",
    "    fig,axes=plt.subplots(nrows=1, ncols=4, figsize=(25,10))\n",
    "    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n",
    "    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n",
    "    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n",
    "    axes[0].scatter(Epochs, tloss, s=100, c='red')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].set_xlabel('Epochs', fontsize=18)\n",
    "    axes[0].set_ylabel('Loss', fontsize=18)\n",
    "    axes[0].legend()\n",
    "    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n",
    "    axes[1].scatter(Epochs, tacc, s=100, c='red')\n",
    "    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n",
    "    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].set_xlabel('Epochs', fontsize=18)\n",
    "    axes[1].set_ylabel('Accuracy', fontsize=18)\n",
    "    axes[1].legend()\n",
    "    axes[2].plot (Epochs,tf1,'r',label= 'Training F1 score')\n",
    "    axes[2].plot (Epochs,vf1,'g',label= 'Validation F1 score')\n",
    "    index_tf1=np.argmax(tf1)#  this is the epoch with the highest training F1 score\n",
    "    tf1max=tf1[index_tf1]\n",
    "    index_vf1=np.argmax(vf1)# thisiis the epoch with the highest validation F1 score\n",
    "    vf1max=vf1[index_vf1]\n",
    "    axes[2].scatter(index_vf1+1 +start_epoch,vf1max, s=150, c= 'blue', label=vc_label)\n",
    "    axes[2].scatter(Epochs, tf1, s=100, c='red')\n",
    "    axes[2].set_title('Training and Validation F1 score')\n",
    "    axes[2].set_xlabel('Epochs', fontsize=18)\n",
    "    axes[2].set_ylabel('F1  score', fontsize=18)\n",
    "    axes[2].legend()\n",
    "    axes[3].plot(Epochs,tauc, 'r', label='Training AUC')\n",
    "    axes[3].plot(Epochs,vauc,'g',label='Validation AUC' )\n",
    "    axes[3].scatter(auc_index+1 +start_epoch,val_highest_auc, s=150, c= 'blue', label=sc_label)\n",
    "    axes[3].scatter(Epochs, tauc, s=100, c='red')\n",
    "    axes[3].set_title('Training and Validation AUC')\n",
    "    axes[3].set_xlabel('Epochs', fontsize=18)\n",
    "    axes[3].set_ylabel('AUC', fontsize=18)\n",
    "    axes[3].legend()\n",
    "    plt.tight_layout\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "tr_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9936d81-f4a4-4045-81c2-d2dc2a8b8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(root + \"working/saved_model2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c83878-1067-421b-a225-9784dfe2a594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
